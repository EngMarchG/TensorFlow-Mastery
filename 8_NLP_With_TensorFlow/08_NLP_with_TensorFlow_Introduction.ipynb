{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP Fundementals in TensorFlow\n",
    "Deriving information out of natural language (sequences text or speech).\n",
    "\n",
    "Another common term for NLP problems is sequence to sequence problems (seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../helper\")\n",
    "from helperFunctions import walk_through_dir, plot_loss_curves, \\\n",
    "    create_tensorboard_callback, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a text dataset\n",
    "\n",
    "The set to be used will be from Kaggle's [Introduction to NLP dataset](https://www.kaggle.com/c/nlp-getting-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./nlp_kaggle/train.csv\")\n",
    "test_df = pd.read_csv(\"./nlp_kaggle/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the test dataframe look like?\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class are there?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Kach was a group to which belonged Baruch Goldstein a mass murderer who in 1994 shot and killed 29 PalestinianÛ_ http://t.co/bXGNQ57xvb\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Rly tragedy in MP: Some live to recount horror: ÛÏWhen I saw coaches of my train plunging into water I called ... http://t.co/CaR5QEUVHH\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Criminals Who Hijack Lorries And Buses Arrested In Enugu (PHOTO) http://t.co/LRTU8Rwn2f\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not are real disaster)\n",
      "Text:\n",
      "@Jannet2208 I fell off someone's back and hit my head on concrete /: I was bleeding n shit\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "#breaking #LA Refugio oil spill may have been costlier bigger than projected http://t.co/5ueCmcv2Pk\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5)\n",
    "\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not are real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                        train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                        test_size=0.1,\n",
    "                                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762, 6851, 762)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the split data\n",
    "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text into numbers\n",
    "When dealing with a text problem, one of the first things that has to be done is to convert text to numbers. This is done by:\n",
    "- Tokenization: direct mapping of token (word or character) to a number\n",
    "- Embedding: create a matrix of feature vector for each token (can be definited by the patterns the model learns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "# Importing it directly from keras to use Pylance till 2.9.0 is released\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "# The default parameters will be used\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # How many words in vocab (None=auto, if out of range when definited, replaced by OOV)\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    ngrams=None, # Create groups of n-words\n",
    "                                    output_mode=\"int\", # How to map tokens to numbers\n",
    "                                    output_sequence_length=None) # How long the sequence of words can be\n",
    "                                    #pad_to_max_tokens=True) # Padds shorter sentences to match the longest and doesn't work if max_token isn't defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokens (words) in the training tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization variables\n",
    "max_vocab_length = 10000 # max number of words in vocabulary\n",
    "max_length = 15 # max length of sequences (how many words from a tweet a model considers)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " @raineishida lol...Im just a nervous wreck :P    \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[9378,    1,   29,    3,    1,  184, 1188,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n {random_sentence}\\\n",
    "    \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "5 most common words in vocab: ['', '[UNK]', 'the', 'a', 'in']\n",
      "5 least common words in vocab: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocabs = text_vectorizer.get_vocabulary() # get all unique words in vocabulary\n",
    "top_5_words = words_in_vocabs[:5] # most commond words \n",
    "bottom_5_words = words_in_vocabs[-5:] # least common words\n",
    "print(f\"Number of words in vocab: {len(words_in_vocabs)}\")\n",
    "print(f\"5 most common words in vocab: {top_5_words}\")\n",
    "print(f\"5 least common words in vocab: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Embedding using an Embedding Layer\n",
    "The most important parameters for tensorflow's embedding layer are:\n",
    "- input_dim = size of the vocab\n",
    "- output_dim = size of the output embedding vector (e.g 100 means a token gets represented by a vector of 100 long)\n",
    "- input_length = length of the sequences being passed to the embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x1b0837ed2b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # output shape (div by 8 good practice\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             embeddings_initializer=\"uniform\")\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "I'm an emotional wreck watching emmerdale    \n",
      "\n",
      "Embedded Version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.04717222,  0.03611494, -0.03517788, ..., -0.01058657,\n",
       "         -0.04965016, -0.01800474],\n",
       "        [-0.01166447, -0.01678411, -0.00245087, ...,  0.04899785,\n",
       "         -0.00505427, -0.03519667],\n",
       "        [ 0.01490821, -0.0095902 , -0.00221124, ...,  0.01198392,\n",
       "         -0.03278033,  0.03485202],\n",
       "        ...,\n",
       "        [-0.0170413 , -0.01058949, -0.01751357, ..., -0.03889031,\n",
       "          0.01332642, -0.02325284],\n",
       "        [-0.0170413 , -0.01058949, -0.01751357, ..., -0.03889031,\n",
       "          0.01332642, -0.02325284],\n",
       "        [-0.0170413 , -0.01058949, -0.01751357, ..., -0.03889031,\n",
       "          0.01332642, -0.02325284]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "    \\n\\nEmbedded Version:\")\n",
    "    \n",
    "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([ 0.04717222,  0.03611494, -0.03517788, -0.04506956, -0.04982939,\n",
       "        -0.02777365,  0.04239173, -0.04537418,  0.00347024,  0.03425818,\n",
       "        -0.01657642,  0.0094107 ,  0.00512083,  0.03208593, -0.02469903,\n",
       "         0.01054115,  0.01845027, -0.04077818,  0.01801801,  0.03424393,\n",
       "         0.04986454,  0.04511473,  0.02904605, -0.03358823,  0.00678096,\n",
       "         0.03641236,  0.02851402, -0.00702752,  0.04305789,  0.02803303,\n",
       "         0.0372803 , -0.02223498, -0.04750078, -0.01237298, -0.01870228,\n",
       "         0.03152995,  0.04435673,  0.03405147, -0.0492523 ,  0.02134592,\n",
       "         0.03138138,  0.03987822,  0.02244799, -0.01945461, -0.0203233 ,\n",
       "        -0.01220961,  0.02792532,  0.03306397,  0.00417261, -0.03423019,\n",
       "        -0.03441127, -0.01346204, -0.01442308, -0.02032653, -0.03247011,\n",
       "        -0.02974182,  0.03528476,  0.01148288,  0.00676139,  0.03544768,\n",
       "        -0.04238475, -0.04148931,  0.02433154, -0.04606751,  0.0257614 ,\n",
       "         0.00774367,  0.04683058,  0.0451887 ,  0.02472201, -0.00850378,\n",
       "        -0.03438914, -0.01466193,  0.00714985,  0.02810161,  0.02792953,\n",
       "         0.01161639,  0.01292003, -0.03167468,  0.00839378,  0.02161748,\n",
       "         0.02821841,  0.02519782,  0.00245221, -0.04846429, -0.0471732 ,\n",
       "         0.00604954,  0.0298645 ,  0.03194727,  0.0303016 , -0.043898  ,\n",
       "         0.03697437, -0.02991773,  0.00717042,  0.02997123, -0.04034889,\n",
       "        -0.02050489,  0.01700664,  0.01319022, -0.01235158, -0.03290506,\n",
       "        -0.0033404 , -0.02185062, -0.01514446, -0.01301543,  0.00738616,\n",
       "         0.02060613,  0.02933628,  0.0178418 ,  0.03309586,  0.02364819,\n",
       "         0.04113389,  0.04481972,  0.0495868 , -0.03762756,  0.01648453,\n",
       "        -0.02672459, -0.04724984,  0.03889722,  0.04146168,  0.01218299,\n",
       "         0.03900233,  0.01147671, -0.0279266 , -0.01065665, -0.0032716 ,\n",
       "        -0.01058657, -0.04965016, -0.01800474], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " \"I'm an emotional wreck watching emmerdale\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling a text dataset (running a series of experiments)\n",
    "\n",
    "Types of models to be built:\n",
    "- Model 0: Naive Bayes (baseline), from Sklearn ML map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "- Model 1: Feed-forward neural network (dense model)\n",
    "- Model 2: LSTM model (RNN)\n",
    "- Model 3: GRU model (RNN)\n",
    "- Model 4: Bidirectional-LSTM model (RNN)\n",
    "- Model 5: 1D Convolutional Neural Network\n",
    "- Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learning)\n",
    "- Model 7: Same as model 6 with 10% of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Baseline\n",
    "Sklearn's multinomial naive bayes using TF-IDF formula to convert words to numbers\n",
    "- It is good practice to use non-DL algorithms as a baseline due to their speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # Convert words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline score is 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"The baseline score is {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function to evaluate some model's predictions using accuracy, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision recall and f1 score of a\n",
    "    binary classification\n",
    "\n",
    "    Args:\n",
    "        y_true (List Bool): true labels of model\n",
    "        y_pred (List Bool): predicted labels of mode\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1-score using \"weighted\" avg\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: A simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard callback (need to create a new one for each model)\n",
    "from helperFunctions import create_tensorboard_callback\n",
    "\n",
    "# Create a directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with the Functional API\n",
    "from keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string) # Input are 1-dimensional string\n",
    "x = text_vectorizer(inputs) # Turn the input to numbers\n",
    "x = embedding(x) # create an embedding of the numberized inputs\n",
    "# x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer want binary outputs so use sigmoid\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20220514-202407\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 7ms/step - loss: 0.6387 - accuracy: 0.6479 - val_loss: 0.5733 - val_accuracy: 0.7677\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.4678 - accuracy: 0.8323 - val_loss: 0.4726 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.3394 - accuracy: 0.8734 - val_loss: 0.4557 - val_accuracy: 0.7887\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2557 - accuracy: 0.9095 - val_loss: 0.4565 - val_accuracy: 0.7874\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1957 - accuracy: 0.9333 - val_loss: 0.4764 - val_accuracy: 0.7900\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model \n",
    "model_1_history = model_1.fit(x=train_sentences,\n",
    "                            y=train_labels,\n",
    "                            epochs=5,\n",
    "                            validation_data=(val_sentences, val_labels),\n",
    "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                experiment_name=\"model_1_dense\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47635507583618164, 0.7900262475013733]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions and evaluate those\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43627816],\n",
       "       [0.79292643],\n",
       "       [0.9930657 ],\n",
       "       [0.06457859],\n",
       "       [0.2519146 ],\n",
       "       [0.9704178 ],\n",
       "       [0.9432973 ],\n",
       "       [0.98718786],\n",
       "       [0.9387273 ],\n",
       "       [0.09305489]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 10 predictions\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.00262467191601,\n",
       " 'precision': 0.7955103864713003,\n",
       " 'recall': 0.7900262467191601,\n",
       " 'f1': 0.7869273549752186}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model predictions to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "\n",
    "# Calculate model_1 results\n",
    "model_1_results = calculate_results(y_pred= model_1_preds,\n",
    "                                    y_true=val_labels)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if model_1 outperforms the baseline\n",
    "# Seems like it isn't\n",
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 1 sumamry\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 128)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the weight matrix of the embedding layer (check summary to see embedding name since rerunning changes it)\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
    "embed_weights.shape # same size as vocab size and embedding_dim (output_dim of embedding layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the TensorFlow projector to visualize the learnt embeddings: http://projector.tensorflow.org\n",
    "\n",
    "TensorFlow has a guide on [embeddings](https://www.tensorflow.org/text/guide/word_embeddings) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding files (taken from embeddings link)\n",
    "import io\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN)\n",
    "RNNs are useful for sequence data.\n",
    "\n",
    "The premise of the network is to use the representation of a previous input to aid the representation of the next inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: LSTM\n",
    "LSTM = Long short term memory (one of the most popular LSTM cells)\n",
    "\n",
    "A typical RNN looks like this:\n",
    "- Input (text) -> Tokenize -> Embedding -> Layers (RNNs/Dense) -> Output (label probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.LSTM(64, return_sequences=True)(x) # when stacking RNN cells together return_seq should be true or else it would return a 2D vector instead of 3D\n",
    "x = layers.LSTM(64)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20220514-202420\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 17ms/step - loss: 0.3726 - accuracy: 0.8393 - val_loss: 0.4843 - val_accuracy: 0.7612\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.2464 - accuracy: 0.9025 - val_loss: 0.5106 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.1703 - accuracy: 0.9383 - val_loss: 0.5823 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.1277 - accuracy: 0.9514 - val_loss: 0.8161 - val_accuracy: 0.7717\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0917 - accuracy: 0.9603 - val_loss: 1.0608 - val_accuracy: 0.7559\n"
     ]
    }
   ],
   "source": [
    "# Compile the model \n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                experiment_name=\"model_2_LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9692406 ],\n",
       "       [0.55084723],\n",
       "       [0.99992466],\n",
       "       [0.00805045],\n",
       "       [0.00102254],\n",
       "       [0.9999275 ],\n",
       "       [0.99280834],\n",
       "       [0.9999759 ],\n",
       "       [0.9999765 ],\n",
       "       [0.1473513 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with LSTM model\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert mdoel 2 pred probs to labels\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.59055118110236,\n",
       " 'precision': 0.7559359047877431,\n",
       " 'recall': 0.7559055118110236,\n",
       " 'f1': 0.7545650097184197}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 2 results\n",
    "model_2_results = calculate_results(val_labels, model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: GRU\n",
    "Gated Recurrent Unit is another popular and effective RNN model\n",
    "\n",
    "The GRU cell has similar features as an LSTM cell, but with less parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an RNN using the GRU cell\n",
    "from keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GRU(64)(x)\n",
    "# Alternative for a more complex model\n",
    "# x = layers.GRU(64, return_sequences=True)(x) # seq set to true for stacking recurrent layers\n",
    "# print(x.shape) # You can see the output if seq isn't true\n",
    "# x = layers.LSTM(64, return_sequences=True)(x)\n",
    "# x = layers.GRU(64)(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20220514-202439\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 12ms/step - loss: 0.2172 - accuracy: 0.9089 - val_loss: 0.6813 - val_accuracy: 0.7717\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1022 - accuracy: 0.9658 - val_loss: 0.7736 - val_accuracy: 0.7730\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.0827 - accuracy: 0.9720 - val_loss: 0.8441 - val_accuracy: 0.7638\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.0690 - accuracy: 0.9731 - val_loss: 0.8311 - val_accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.0530 - accuracy: 0.9765 - val_loss: 1.2330 - val_accuracy: 0.7638\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the mode\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(\n",
    "                                  SAVE_DIR,\n",
    "                                  \"model_3_GRU\"\n",
    "                              )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the GRU model\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "\n",
    "# Convert model 3 predictions to labels\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.37795275590551,\n",
       " 'precision': 0.7639261289761722,\n",
       " 'recall': 0.7637795275590551,\n",
       " 'f1': 0.7624822674694383}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 3 results\n",
    "model_3_results = calculate_results(val_labels, model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_4: Bidirectional RNN\n",
    "Normal RNNs go from left to right (just like you'd read an English sentence). However, a bidirectional RNN, additionally goes from right to left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a bidirectional RNN in tensorflow\n",
    "from keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"input_layer\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.GRU(64))(x) \n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"Bidirectional_RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Bidirectional_RNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              74496     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,354,625\n",
      "Trainable params: 1,354,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20220514-202453\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 16ms/step - loss: 0.1526 - accuracy: 0.9432 - val_loss: 0.8249 - val_accuracy: 0.7625\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0670 - accuracy: 0.9740 - val_loss: 0.9871 - val_accuracy: 0.7598\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0542 - accuracy: 0.9769 - val_loss: 1.3352 - val_accuracy: 0.7612\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0493 - accuracy: 0.9781 - val_loss: 1.2185 - val_accuracy: 0.7598\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0443 - accuracy: 0.9780 - val_loss: 1.3122 - val_accuracy: 0.7454\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(\n",
    "                                  SAVE_DIR, \"model_4_bidirectional\"\n",
    "                              )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3230823e-04],\n",
       "       [7.8821719e-01],\n",
       "       [9.9988317e-01],\n",
       "       [1.0391406e-01],\n",
       "       [4.4552027e-05]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict using the model\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 74.54068241469817,\n",
       " 'precision': 0.745282272536504,\n",
       " 'recall': 0.7454068241469817,\n",
       " 'f1': 0.7440086660503947}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the predictions\n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.37795275590551,\n",
       " 'precision': 0.7639261289761722,\n",
       " 'recall': 0.7637795275590551,\n",
       " 'f1': 0.7624822674694383}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model_4 is even worse than model_3!!\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_5: 1D Convolutional Neural Network\n",
    "CNNs were made previously, however, it was for 2D images. Text data is 1D.\n",
    "\n",
    "Conv1D is used in this case for text and it looks like this\n",
    "```\n",
    "Inputs (text) -> Tokenization -> Embedding -> Layers (typically Conv1D + pooling) -> Outputs (class probs)\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out the embedding layer, Conv1D and max pooling\n",
    "from keras import layers\n",
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # Turn target to embedding\n",
    "conv_1d = layers.Conv1D(filters=32,\n",
    "                        kernel_size=5,\n",
    "                        activation=\"relu\",\n",
    "                        padding=\"valid\")\n",
    "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
    "max_pool = layers.GlobalMaxPooling1D()\n",
    "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get most important feature/highest value\"\n",
    "\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For conv layers:\n",
    "\n",
    "Difference between same padding and valid padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 1D Conv model\n",
    "from keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"input_layer\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(filters=64, # Written in same order as in the function\n",
    "                 kernel_size=5,\n",
    "                 strides=1,\n",
    "                 padding=\"same\", # Keeps all the info and adds 0 paddings\n",
    "                 activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Conv1D/20220514-202513\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 9ms/step - loss: 0.1403 - accuracy: 0.9647 - val_loss: 0.8414 - val_accuracy: 0.7664\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0672 - accuracy: 0.9756 - val_loss: 0.9243 - val_accuracy: 0.7638\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0545 - accuracy: 0.9771 - val_loss: 1.1018 - val_accuracy: 0.7572\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0524 - accuracy: 0.9790 - val_loss: 1.0702 - val_accuracy: 0.7480\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0505 - accuracy: 0.9796 - val_loss: 1.1157 - val_accuracy: 0.7480\n"
     ]
    }
   ],
   "source": [
    "# Compile the Conv1D\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data = (val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(\n",
    "                                  SAVE_DIR, \"Conv1D\"\n",
    "                              )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 15, 64)            41024     \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321,089\n",
      "Trainable params: 1,321,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.4400939e-02],\n",
       "       [9.0064991e-01],\n",
       "       [9.9969137e-01],\n",
       "       [3.6925960e-02],\n",
       "       [8.6281580e-06]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions with Conv1D\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 74.80314960629921,\n",
       " 'precision': 0.7475602233434432,\n",
       " 'recall': 0.7480314960629921,\n",
       " 'f1': 0.7472754780275664}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 5 to labels and evaluate\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_results = calculate_results(val_labels, model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 74.54068241469817,\n",
       " 'precision': 0.745282272536504,\n",
       " 'recall': 0.7454068241469817,\n",
       " 'f1': 0.7440086660503947}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_6: Transfer Learning\n",
    "There are different types of models for NLP\n",
    "- Hugging face trasnformers\n",
    "- Universal Sentence Encoder\n",
    "- Other models on the tfhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01157027  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
      "  0.02680985  0.05589838 -0.01068729 -0.00597292  0.00639323 -0.0181952\n",
      "  0.00030814  0.09105888  0.05874645 -0.03180628  0.01512474 -0.05162929\n",
      "  0.00991367 -0.06865346], shape=(20,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embed_samples = embed([sample_sentence,\"This is a test sentence\"])\n",
    "print(embed_samples[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Layer using the USE pretrained model\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile the model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20220514-202538\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 20ms/step - loss: 0.5047 - accuracy: 0.7821 - val_loss: 0.4615 - val_accuracy: 0.7913\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4139 - accuracy: 0.8168 - val_loss: 0.4401 - val_accuracy: 0.8110\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4005 - accuracy: 0.8213 - val_loss: 0.4348 - val_accuracy: 0.8071\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.3912 - accuracy: 0.8297 - val_loss: 0.4279 - val_accuracy: 0.8123\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.3849 - accuracy: 0.8298 - val_loss: 0.4285 - val_accuracy: 0.8176\n"
     ]
    }
   ],
   "source": [
    "# Fit the reinforced model\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(\n",
    "                                  SAVE_DIR, \"tf_hub_sentence_encoder\"\n",
    "                              )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17359671],\n",
       "       [0.73940265],\n",
       "       [0.9862343 ],\n",
       "       [0.18700214],\n",
       "       [0.72474706]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict using the model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.75853018372703,\n",
       " 'precision': 0.8209627063084894,\n",
       " 'recall': 0.8175853018372703,\n",
       " 'f1': 0.8157737537147242}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert it to labels and evaluate\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_7: TF Pretrained USE but using 10% of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you uncomment the other 10% data in the below cell.\n",
    "\n",
    "Model 7 is doing better than model 6 despite having 10% of the data!!\n",
    "\n",
    "Something seems off.\n",
    "Looking back the 10% data was made off of the whole dataset. \n",
    "\n",
    "Yes, both times while splitting the whole dataset and taking 10% of it was done randomly, there seems to be some data leakage (val sentence in training)\n",
    "\n",
    "DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAIN SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a 10% data subset\n",
    "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
    "# # train_10_percent.head(), len(train_10_percent)\n",
    "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
    "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
    "# len(train_sentences_10_percent), len(train_labels_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of targets in the subset data\n",
    "# train_10_percent[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a better dataset split (no data leakage)\n",
    "train_10_percent_split = int(0.1 * len(train_sentences))\n",
    "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
    "train_labels_10_percent = train_labels[:train_10_percent_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    406\n",
       "1    279\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of each label in the updated training data subset\n",
    "# Imbalanced ratio but workable\n",
    "pd.Series(np.array(train_labels_10_percent)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate the model same as the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the same model\n",
    "# model_7 = tf.keras.models.clone_model(model_6)\n",
    "model_7 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
    "], name=\"model_7_USE\") # Copied to change the name\n",
    "\n",
    "# Compile model\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent/20220514-202600\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 61ms/step - loss: 0.6766 - accuracy: 0.6628 - val_loss: 0.6524 - val_accuracy: 0.7283\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.6100 - accuracy: 0.8044 - val_loss: 0.5976 - val_accuracy: 0.7638\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.5352 - accuracy: 0.8146 - val_loss: 0.5430 - val_accuracy: 0.7861\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.4727 - accuracy: 0.8161 - val_loss: 0.5093 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 37ms/step - loss: 0.4282 - accuracy: 0.8234 - val_loss: 0.4913 - val_accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the 10% data subset\n",
    "model_7_history = model_7.fit(train_sentences_10_percent,\n",
    "                              train_labels_10_percent,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(\n",
    "                                  SAVE_DIR, \"tf_hub_sentence_encoder_10_percent\"\n",
    "                              )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the model\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.69028871391076,\n",
       " 'precision': 0.7779652793701148,\n",
       " 'recall': 0.7769028871391076,\n",
       " 'f1': 0.7752416323647977}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model 7\n",
    "model_7_results = calculate_results(val_labels, model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.75853018372703,\n",
       " 'precision': 0.8209627063084894,\n",
       " 'recall': 0.8175853018372703,\n",
       " 'f1': 0.8157737537147242}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results make sense now. Still, with only 10% of the data the prediction is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the performance of eac model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
    "                                \"1_simple_dense\": model_1_results,\n",
    "                                \"2_lstm\": model_2_results,\n",
    "                                \"3_gru\": model_3_results,\n",
    "                                \"4_bidirectional\": model_4_results,\n",
    "                                \"5_con1d\": model_5_results,\n",
    "                                \"6_tf_hub_use_encoder\": model_6_results,\n",
    "                                \"6_tf_hub_use_encoder\": model_6_results,\n",
    "                                \"7_tf_hub_encoder\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the accuracy to the same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1_score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", \\\n",
    "    figsize=(10,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the model training logs to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/hkNc5NubTLWFX575YSeVwA/\n",
      "\n",
      "\u001b[1m[2022-05-14T20:12:18]\u001b[0m Started scanning logdir.\n",
      "\u001b[2K\u001b[32mData upload starting...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (68.8 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (61.6 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (61.3 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (61.3 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (397.9 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (233.9 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (422.0 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (904.8 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (904.8 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (905.1 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading binary object (905.1 kB)...\u001b[0m\n",
      "\u001b[2K\u001b[32mUploading 330 scalars...\u001b[0m\n",
      "\u001b[1m[2022-05-14T20:12:31]\u001b[0m Total uploaded: 330 scalars, 0 tensors, 11 binary objects (4.8 MB)\n",
      "\u001b[1m[2022-05-14T20:12:31]\u001b[0m Done scanning logdir.\n",
      "\n",
      "\n",
      "Done. View your TensorBoard at https://tensorboard.dev/experiment/hkNc5NubTLWFX575YSeVwA/\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir ./model_logs/ \\\n",
    "    --name \"NLP Modelling Experiments\" \\\n",
    "    --description \"Comparing different model architectures on Kaggle's tweet text classification data set\" \\\n",
    "    --one_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading a trained model\n",
    "The two main models of saving a model in tensorflow\n",
    "1. HDF5 format\n",
    "2. SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"/saved_models/model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with custom \n",
    "import tensorflow_hub as hub\n",
    "loaded_model_6 = tf.keras.models.load_model(\"/saved_models/model_6.h5\",\n",
    "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the loaded model perform\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to SavedModel format (default)\n",
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model in SavedModel format\n",
    "loaded_model_6_SavedModel_format.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the most wrong examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example if a sample should have a label of 0 and predicts 0.99 and vice versa (model-driven data exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "24/24 [==============================] - 2s 16ms/step - loss: 0.4272 - accuracy: 0.8163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42723119258880615, 0.8162729740142822]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the universal model\n",
    "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
    "model_6_pretrained.evaluate(val_sentences, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the loaded model form globals\n",
    "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
    "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
    "model_6_pretrained_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Investigators rule catastrophic structural fai...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.709675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How the West was burned: Thousands of wildfire...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Map: Typhoon Soudelor's predicted path as it a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ûª93 blasts accused Yeda Yakub dies in Karach...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My ears are bleeding  https://t.co/k5KnNwugwT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  pred  pred_probs\n",
       "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0    0.159757\n",
       "1  FedEx no longer to transport bioterror germs i...       0   1.0    0.747162\n",
       "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0    0.988749\n",
       "3  @camilacabello97 Internally and externally scr...       1   0.0    0.196229\n",
       "4  Radiation emergency #preparedness starts with ...       1   1.0    0.707808\n",
       "5  Investigators rule catastrophic structural fai...       1   1.0    0.709675\n",
       "6  How the West was burned: Thousands of wildfire...       1   1.0    0.981907\n",
       "7  Map: Typhoon Soudelor's predicted path as it a...       1   1.0    0.981066\n",
       "8  Ûª93 blasts accused Yeda Yakub dies in Karach...       1   1.0    0.945744\n",
       "9      My ears are bleeding  https://t.co/k5KnNwugwT       0   0.0    0.085040"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with validation sentences and best performing model prediction labels + probs\n",
    "val_df = pd.DataFrame({\"text\": val_sentences,\n",
    "                    \"target\": val_labels,\n",
    "                    \"pred\": model_6_pretrained_preds,\n",
    "                    \"pred_probs\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
    "val_df[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.910196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.876982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.827213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
       "\n",
       "     pred_probs  \n",
       "31     0.910196  \n",
       "759    0.876982  \n",
       "628    0.852300  \n",
       "209    0.835454  \n",
       "251    0.827213  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong = val_df[val_df[\"pred\"]!=val_df[\"target\"]].sort_values(\"pred_probs\", ascending=False)\n",
    "df_wrong.head() # False positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I get to smoke my shit in peace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Why are you deluged with low self-image? Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
       "233                    I get to smoke my shit in peace       1   0.0   \n",
       "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
       "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
       "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
       "\n",
       "     pred_probs  \n",
       "411    0.043918  \n",
       "233    0.042087  \n",
       "38     0.038998  \n",
       "244    0.038949  \n",
       "23     0.037186  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong.tail() # False negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target labels:\n",
    "- 0 = not disaster\n",
    "- 1 = disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Pred: 1.0, Prob: 0.9101957678794861\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8769820928573608\n",
      "Text:\n",
      "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8523000478744507\n",
      "Text:\n",
      "@noah_anyname That's where the concentration camps and mass murder come in. \n",
      " \n",
      "EVERY. FUCKING. TIME.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8354543447494507\n",
      "Text:\n",
      "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8272132873535156\n",
      "Text:\n",
      "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8148158192634583\n",
      "Text:\n",
      "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8108396530151367\n",
      "Text:\n",
      "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.80312180519104\n",
      "Text:\n",
      "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.7669007182121277\n",
      "Text:\n",
      "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.7666251063346863\n",
      "Text:\n",
      "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false positives (model predicted 1 when should've been 0)\n",
    "for row in df_wrong[:10].itertuples():\n",
    "    _, text, target, pred, pred_probs = row\n",
    "    print(f\"Target: {target}, Pred: {pred}, Prob: {pred_probs}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0.0, Prob: 0.06730346381664276\n",
      "Text:\n",
      "@DavidVonderhaar At least you were sincere ??\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.05507579818367958\n",
      "Text:\n",
      "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.05460337549448013\n",
      "Text:\n",
      "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.05459696426987648\n",
      "Text:\n",
      "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.049637261778116226\n",
      "Text:\n",
      "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.043918490409851074\n",
      "Text:\n",
      "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.04208684340119362\n",
      "Text:\n",
      "I get to smoke my shit in peace\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.03899792954325676\n",
      "Text:\n",
      "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.03894945606589317\n",
      "Text:\n",
      "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.037185799330472946\n",
      "Text:\n",
      "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false positives (model predicted 1 when should've been 0)\n",
    "for row in df_wrong[-10:].itertuples():\n",
    "    _, text, target, pred, pred_probs = row\n",
    "    print(f\"Target: {target}, Pred: {pred}, Prob: {pred_probs}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict tweets on the wild\n",
    "Try using the model on some tweets found online and see if it predicts correctly or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The speed/score tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the time of prediction \n",
    "import time \n",
    "def pred_timer(model, samples):\n",
    "    \"\"\"\n",
    "    Times how long a model takes to make predictions on samples.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.model): The model that will predict the labels\n",
    "        samples (List of strings): The samples the model will use\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter() # get start time\n",
    "    model.predict(samples) # make predictions\n",
    "    end_time = time.perf_counter() # get finish time\n",
    "    total_time = end_time-start_time # calculate how long prediction took\n",
    "    time_per_pred = total_time/len(samples)\n",
    "    return total_time, time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4613787999999204, 0.0006054839895012078)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TF Hub Sentence Encoder time per pred\n",
    "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model=model_6_pretrained,\n",
    "                                                    samples=val_sentences)\n",
    "model_6_total_pred_time, model_6_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.62729658792651,\n",
       " 'precision': 0.818446310697231,\n",
       " 'recall': 0.8162729658792651,\n",
       " 'f1': 0.8148082644367335}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_pretrained_results = calculate_results(val_labels, model_6_pretrained_preds)\n",
    "model_6_pretrained_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.011641099999906146, 1.527703412061174e-05)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the baseline model times per pred\n",
    "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0,\n",
    "                                                        val_sentences)\n",
    "baseline_total_pred_time, baseline_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1-score')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
    "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label=\"model_6\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time per prediction\")\n",
    "plt.ylabel(\"F1-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d974c4b7c9167b3c2df7ef2f40c9ab050914ef25a32a81d1263224e0dc77032"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
